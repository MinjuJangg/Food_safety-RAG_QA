from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, GenerationConfig
import pandas as pd
import json
import time
import re
import torch

# ëª¨ë¸ ë¡œë“œ
model_name = "google/gemma-2-9b-it"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
gen_config = GenerationConfig(
    temperature=0.5,
    top_p=0.7,
    top_k=40,
    max_new_tokens=1024,
    do_sample=True
)

gemma_pipeline = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    return_full_text=False,
    generation_config=gen_config
)

# í…ìŠ¤íŠ¸ ì •ë¦¬
def clean_text(text):
    return str(text).replace('"', "'").strip()

# ğŸ’¬ Gemini ìŠ¤íƒ€ì¼ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ìƒì„±
def make_prompt(title, content):
    return f"""ë„ˆëŠ” ë¬¸ì„œ ê¸°ë°˜ QA ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë„ìš°ë¯¸ì•¼. ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ ì§ˆë¬¸(Query)ê³¼ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€(Answer) ìŒì„ ì¶”ì¶œí•´ì•¼ í•´. íŠ¹íˆ **ê°€ì¥ í•µì‹¬ì ì´ê±°ë‚˜ ì¤‘ìš”í•œ ì§ˆë¬¸ 1ê°œë§Œ** ìƒì„±í•´ì•¼ í•˜ë©°, ì´ëŠ” **ì‚¬ëŒì´ ì´ ë¬¸ì„œë¥¼ ë´¤ì„ ë•Œ ê°€ì¥ ë¨¼ì € ê¶ê¸ˆí•´í•  ì§ˆë¬¸**ì´ì–´ì•¼ í•´. ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì‹œì˜¤.

ì œëª©: {clean_text(title)}
ë‚´ìš©: {clean_text(content)}

### ì¶œë ¥ í˜•ì‹
[
 { {"query": "ì‹¤ì œ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸", "answer": "ë¬¸ì„œì—ì„œ í™•ì¸ëœ ë‹µë³€"}}
]

### ìƒì„± ê·œì¹™
1. ì§ˆë¬¸ì€ ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ëŒì´ ì‹¤ì œë¡œ ê¶ê¸ˆí•´í•  ë§Œí•œ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì¸ìœ„ì ì¸ íŒ¨í„´ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.
2. ë‹µë³€ì€ ë°˜ë“œì‹œ í•´ë‹¹ ë¬¸ì„œì—ì„œ ì§ì ‘ í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì„ ì¶”ì¸¡í•˜ê±°ë‚˜ ì™¸ì‚½í•˜ì§€ ë§ˆì„¸ìš”.
3. ë¬¸ì„œì—ì„œ ë‹µì´ ëª…í™•íˆ ì£¼ì–´ì§€ì§€ ì•Šì€ ê²½ìš°, ë‹µë³€ì€ "í•´ë‹¹ ë¬¸ì„œì— ì—†ìŒ"ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
4. í•œ ë¬¸ì„œë‹¹ í•˜ë‚˜ì˜ ì§ˆë¬¸-ë‹µë³€ ìŒë§Œ ìƒì„±í•˜ì„¸ìš”.
5. ì§ˆë¬¸ì€ ì„œë¡œ ë‹¤ë¥¸ ì •ë³´ì— ì´ˆì ì„ ë§ì¶° ë‹¤ì–‘í•˜ê²Œ êµ¬ì„±í•˜ì„¸ìš”. 
   - ì˜ˆ: ì œí’ˆëª…, ì œì¡°ì‚¬, ìœ í†µ ê²½ë¡œ, ì¼ì, íšŒìˆ˜ ì‚¬ìœ , ë²• ìœ„ë°˜ í•­ëª©, ëŒ€í‘œì ë“±
6. í•˜ë‚˜ì˜ ì§ˆë¬¸ì— ë„ˆë¬´ ë§ì€ ìš”ì†Œë¥¼ ë‹´ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í•˜ë‚˜ì˜ ì •ë³´ë§Œ ë¬¼ì–´ë³´ë„ë¡ í•˜ì„¸ìš”.
7. ì§ˆë¬¸ì€ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë‹¨ë¬¸ì´ë‚˜ ëª…ë ¹ë¬¸ í˜•íƒœëŠ” í”¼í•˜ì„¸ìš”.
8. ì§ˆë¬¸ ë¬¸ì¥ì€ ìœ ì‚¬í•˜ê±°ë‚˜ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ í•˜ë©°, ì‚¬ëŒìŠ¤ëŸ¬ìš´ ë¬¸ì¥ íë¦„ì„ ê°–ì¶”ì„¸ìš”.
9. 'íšŒìˆ˜ ì‚¬ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?' í˜•ì‹ì˜ ì§ˆë¬¸ì„ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”. í‘œí˜„ì„ ë‹¤ì–‘í™”í•˜ì—¬ ì‚¬ëŒë‹¤ìš´ ë§íˆ¬ë¡œ ë°”ê¾¸ì„¸ìš”.
10. ì§ˆë¬¸ì—ëŠ” 'ì´ë²ˆ', 'í•´ë‹¹', 'ì´ ì œí’ˆ'ê³¼ ê°™ì€ ëª¨í˜¸í•œ ì§€ì‹œì–´ ëŒ€ì‹ , ì§ˆë¬¸ì˜ ëŒ€ìƒì´ ëª…í™•íˆ ë“œëŸ¬ë‚˜ë„ë¡ í•˜ì„¸ìš”. ë‹¤ë§Œ, ì§ˆë¬¸ì´ ê³¼ë„í•˜ê²Œ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ì œí’ˆëª…ì´ë‚˜ ê¸°ê´€ëª… ë“±ì€ ê°„ê²°í•˜ê²Œ í•„ìš”í•œ ë§Œí¼ë§Œ í¬í•¨í•˜ì„¸ìš”.
11. ì£¼ì–´ì§„ ì œëª©, ë‚´ìš© ì™¸ ì˜ˆì‹œë¥¼ ìƒì„±í•˜ì§€ ë§ˆì‹œì˜¤.
12. ì¶œë ¥ í˜•ì‹ ì™¸ ë‹¤ë¥¸ ë‚´ìš©ì€ ì¶œë ¥í•˜ì§€ ë§ˆì‹œì˜¤.
"""

# ğŸ” ëª¨ë¸ ì‘ë‹µì—ì„œ JSON ë°°ì—´ë§Œ ì¶”ì¶œ
def extract_json_from_response(response_text):
    try:
        match = re.search(r"\[\s*{.*?}\s*]", response_text, re.DOTALL)
        if match:
            json_str = match.group().replace("'", '"')
            return json.loads(json_str)

        else:
            raise ValueError("JSON í˜•ì‹ì˜ QA ìŒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

# ğŸ§  Gemmaë¥¼ ì´ìš©í•œ QA ì¶”ì¶œ
def get_qa_from_document(title, content):
    prompt = make_prompt(title, content)
    print("====prompt")
    print(prompt)
    try:
        result = gemma_pipeline(prompt)[0]["generated_text"]
        response_text = result.strip()
        print("=== ì›ë³¸ ì‘ë‹µ ===")
        print(response_text)

        qa_list = extract_json_from_response(response_text)
        print("=== ì¶”ì¶œëœ QA ===")
        print(qa_list)

        return qa_list

    except Exception as e:
        print("QA ìƒì„± ì‹¤íŒ¨:", e)
        print("ì›ë³¸ ì‘ë‹µ:", result if 'result' in locals() else "ì—†ìŒ")
        return []

# CSV íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
file_path = "/home/food/people/minju/data/make_qa/real_final.csv"
df = pd.read_csv(file_path)

# QA ì»¬ëŸ¼ ì¶”ê°€
df["gemma_query"] = ""
df["gemma_answer"] = ""

# ë£¨í”„ QA ìƒì„±
for i in range(len(df)):
    print(f"\n\\ [{i+1}/{len(df)}] QA ìƒì„± ì¤‘...")

    title = df.loc[i, "title"] if "title" in df.columns else ""
    text = df.get("document", df.get("extracted_text", ""))[i]

    if pd.isna(text) or len(str(text).strip()) < 5:
        print("ë¬¸ì„œê°€ ë¹„ì–´ ìˆìŒ. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        continue

    qa_pairs = get_qa_from_document(title, text)

    if qa_pairs:
        queries = [pair["query"] for pair in qa_pairs]
        answers = [pair["answer"] for pair in qa_pairs]
        df.at[i, "gemma_query"] = "\n".join(queries)
        df.at[i, "gemma_answer"] = "\n".join(answers)

    time.sleep(1)

# ê²°ê³¼ ì €ì¥
df.to_csv("real_final_with_gemma_QA.csv", index=False)
print("\nì €ì¥ ì™„ë£Œ: real_final_with_gemma_QA.csv")
